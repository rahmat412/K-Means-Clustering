{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "IMPORT LIBRARY AND DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvUek4Q9zONt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "\r\n",
        "from kneed import KneeLocator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "RjygD3zlzON0",
        "outputId": "e60cf12b-e41e-4312-c851-fa0466f42762"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('kendaraan_train.csv')\r\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DATA EXPLORARTION AND PREPROCESSING DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop column 'id'\r\n",
        "df_pre = df.drop('id', axis=1)\r\n",
        "\r\n",
        "# check the duplicate rows and missing values\r\n",
        "print('Duplicated row count: %d' %df_pre.duplicated().sum())\r\n",
        "print('Missing values\\n%s' %df_pre.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop the duplicate rows and missing values\r\n",
        "df_pre = df_pre.drop_duplicates()\r\n",
        "df_pre = df_pre.dropna()\r\n",
        "df_pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check features datatype\r\n",
        "df_pre.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encoding the data in column 'Jenis_Kelamin', 'Umur_Kendaraan', and 'Kendaraan_Rusak'\r\n",
        "object_columns = ['Jenis_Kelamin', 'Umur_Kendaraan', 'Kendaraan_Rusak']\r\n",
        "for column in object_columns:\r\n",
        "    df_pre[column] = LabelEncoder().fit_transform(df_pre[column])\r\n",
        "df_default = df_pre\r\n",
        "df_pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scaler the data with standard scaler\r\n",
        "df_pre = StandardScaler().fit_transform(df_pre)\r\n",
        "df_pre = pd.DataFrame(df_pre)\r\n",
        "df_pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert the multiple columns into two columns with PCA\r\n",
        "pca = PCA(n_components=2)\r\n",
        "df_pre = pca.fit_transform(df_pre)\r\n",
        "df_pre = pd.DataFrame(df_pre)\r\n",
        "df_pre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# change the dataframe into list\r\n",
        "X = df_pre.values\r\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CLUSTERING, K-MEANS (TASK 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class KMeans:\r\n",
        "  def __init__(self, k, max_iter=100, tol=0.001):\r\n",
        "    self.k = k\r\n",
        "    self.max_iter = max_iter\r\n",
        "    self.tol = tol\r\n",
        "\r\n",
        "  # calculate the distance using euclidean distance method\r\n",
        "  def euclidean_dist(self,x1,x2):\r\n",
        "    return np.linalg.norm(x1-x2)\r\n",
        "\r\n",
        "  # use randomly initilialize the centroids\r\n",
        "  def initialize_centroids(self, data):\r\n",
        "    init_centroids = []\r\n",
        "    idx = []\r\n",
        "    for _ in range(self.k):\r\n",
        "      idx.append(np.random.randint(0,data.shape[0]))\r\n",
        "    init_centroids = (X[idx])\r\n",
        "    return init_centroids\r\n",
        "\r\n",
        "  def fit(self, data):\r\n",
        "    self.clusters = {}\r\n",
        "    #initialize the centroids randomly\r\n",
        "    self.centroids = self.initialize_centroids(data)\r\n",
        "    #assign each row to a centroid and recalculate centroids until there is no change or we reach the most iterations we wanna do\r\n",
        "    iter = 0\r\n",
        "    while iter < self.max_iter:\r\n",
        "      #create the clusters (empty in the beginning)\r\n",
        "      self.clusters.clear()\r\n",
        "      \r\n",
        "      #fill the clusters by adding the appropriate row to the cluster associated with the closest centroid\r\n",
        "      for row in data:\r\n",
        "        dist = []\r\n",
        "        for i in range(len(self.centroids)):\r\n",
        "            dist.append(self.euclidean_dist(self.centroids[i],row))\r\n",
        "        idx = dist.index(min(dist))\r\n",
        "        self.clusters.setdefault(idx,[]).append(list(row))\r\n",
        "      \r\n",
        "      #store the previous centroids\r\n",
        "      old_centroids = self.centroids.copy()\r\n",
        "\r\n",
        "      #recalculate the new centroids\r\n",
        "      for centroid in range(len(self.centroids)):\r\n",
        "        self.centroids[centroid] = np.average(self.clusters[centroid],axis=0)\r\n",
        "\r\n",
        "      #check if the centroids have moved according to the amount of slack\r\n",
        "      diff = []\r\n",
        "      for centroid in range(len(self.centroids)):\r\n",
        "        old_centroid = old_centroids[centroid]\r\n",
        "        diff.append(np.sum(abs((self.centroids[centroid]-old_centroid))))\r\n",
        "\r\n",
        "      if sum(diff) <= self.tol:\r\n",
        "        break\r\n",
        "      \r\n",
        "      #increment number of iterations    \r\n",
        "      iter += 1\r\n",
        "\r\n",
        "    print(\"Iterations:\", iter)\r\n",
        "    for k in range(self.k):\r\n",
        "        self.clusters[k] = np.array(self.clusters[k])\r\n",
        "  \r\n",
        "  # to find the sum of square errors\r\n",
        "  def inertia(self):\r\n",
        "    errors = []\r\n",
        "    for i in range(len(self.centroids)):\r\n",
        "      cluster_error = 0\r\n",
        "      for j in range(len(self.clusters[i])):\r\n",
        "        cluster_error += self.euclidean_dist(self.centroids[i],self.clusters[i][j])\r\n",
        "      errors.append(cluster_error)\r\n",
        "    return sum(errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to plot the elbow method\r\n",
        "def plot_elbow(k_range, sse):\r\n",
        "  plt.figure(figsize=(20,10))\r\n",
        "  plt.plot(list(k_range),sse,marker='o',markerfacecolor='orange',markersize=10,lw=5,color='blue')\r\n",
        "  plt.title('Elbow Curve')\r\n",
        "  plt.xlabel('Number of Clusters')\r\n",
        "  plt.ylabel('SSE')\r\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to plot the cluster model\r\n",
        "def plot_clusters(model, xl, yl):\r\n",
        "  colors = [\"red\",\"green\",\"blue\",\"cyan\",\"magenta\",\"yellow\",\"pink\",\"orange\",\"purple\",\"brown\"]\r\n",
        "  labels = ['Cluster-1','Cluster-2','Cluster-3','Cluster-4','Cluster-5','Cluster-6','Cluster-7','Cluster-8','Cluster-9','Cluster-10']\r\n",
        "  plt.figure(figsize=(20,10))\r\n",
        "  for k in range(len(model.centroids)):\r\n",
        "    plt.scatter(model.clusters[k][:,0], model.clusters[k][:,1],c=colors[k],label=labels[k], s = 30, alpha=0.4)\r\n",
        "  plt.scatter(model.centroids[:,0], model.centroids[:,1],c=\"black\",label=\"Centroid\", s = 150, marker = \"X\")\r\n",
        "  plt.xlabel(xl)\r\n",
        "  plt.ylabel(yl)\r\n",
        "  plt.legend()\r\n",
        "  plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# form the model from the dataset with range k is 2-10\r\n",
        "k_models = []\r\n",
        "k_range = range(2,11)\r\n",
        "for i in k_range:\r\n",
        "    print(\"K =\",i)\r\n",
        "    model = KMeans(k=i,max_iter=100,tol=0.001)\r\n",
        "    model.fit(X)\r\n",
        "    k_models.append(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot the elbow method based on inertia of the models\r\n",
        "sse = [k.inertia() for k in k_models]\r\n",
        "plot_elbow(k_range,sse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# find the elbow curve using kneelocator\r\n",
        "kl = KneeLocator(k_range,sse,curve=\"convex\",direction=\"decreasing\")\r\n",
        "opt = kl.elbow\r\n",
        "print(\"Optimal K:\", opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# x and y label\r\n",
        "xl = 'PCA-0'\r\n",
        "yl = 'PCA-1'\r\n",
        "\r\n",
        "# plot the original data with pca\r\n",
        "plt.figure(figsize=(20,10))\r\n",
        "plt.scatter(X[:,0],X[:,1], s = 30, alpha=0.4)\r\n",
        "plt.xlabel(xl)\r\n",
        "plt.ylabel(yl)\r\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot the model with optimal k\r\n",
        "opt_k = k_models[opt-2]\r\n",
        "plot_clusters(opt_k,xl,yl)\r\n",
        "print(opt_k.centroids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collecting the explored data in a dataframe\r\n",
        "temp = []\r\n",
        "conc = np.vstack(opt_k.clusters)\r\n",
        "for i in range(len(conc)):\r\n",
        "  lst = (opt_k.clusters[conc[i][0]]).tolist()\r\n",
        "  for j in range(len(lst)):\r\n",
        "    lst[j].append(conc[i][0]+1)\r\n",
        "  temp.append(lst)\r\n",
        "\r\n",
        "frames=[]\r\n",
        "for v in range(len(temp)):\r\n",
        "  temp2 = (pd.DataFrame(temp[v], columns = [xl, yl,'Cluster']))\r\n",
        "  frames.append(temp2)\r\n",
        "result = pd.concat(frames,ignore_index = True)\r\n",
        "\r\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort the data by default data\r\n",
        "result = result.set_index(xl)\r\n",
        "result = result.reindex(index=df_pre[0])\r\n",
        "result = result.reset_index()\r\n",
        "result = result.rename(columns = {0:xl})\r\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# assign 'Cluster' label into default data\r\n",
        "df_default['Cluster'] = result['Cluster'].values\r\n",
        "df_default['Cluster'] = df_default['Cluster'].astype(int)\r\n",
        "df_default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# group the cluster value and see the mean value of each of the attributes in the dataset using the 'mean' method\r\n",
        "demographic = df_default.groupby('Cluster').mean()\r\n",
        "demographic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "demographic.to_csv('export_demo_cluster_kendaraan.csv', index=True, header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# export the explored data into csv file\r\n",
        "df_default.to_csv('export_cluster_kendaraan.csv', index=False, header=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "k-means_scratch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 32-bit",
      "name": "python38232bitcf9bca7eb21a426b9db4a2bceb84ec88"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "metadata": {
      "interpreter": {
        "hash": "13fdf25ef2beee923e1f1011635d38d6ce68fb2882c6a64f76de1420ab9cc9f4"
      }
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 0
}